{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from tsfresh import extract_features, extract_relevant_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "hrs=3\n",
    "candlestick_frame = 4*hrs\n",
    "pnl_threshold = 3\n",
    "df = pd.read_csv('../../data/BTCUSDT.csv')\n",
    "\n",
    "ts = list(df['time'])\n",
    "open = list(df['open'])\n",
    "high = list(df['high'])\n",
    "low = list(df['low'])\n",
    "close = list(df['close'])\n",
    "volume = list(df['volume'])\n",
    "tot = len(ts)\n",
    "long_runup_lst = []\n",
    "long_drawdown_lst = []\n",
    "short_runup_lst = []\n",
    "short_drawdown_lst = []\n",
    "\n",
    "for idx in range(tot):\n",
    "    if (idx >= candlestick_frame) and (idx <= tot - candlestick_frame):\n",
    "        max_high = max(open[idx+1:idx+candlestick_frame])\n",
    "        min_low = min(open[idx+1:idx+candlestick_frame])\n",
    "        entry_price = open[idx+1]\n",
    "        long_runup_lst.append(round((max_high*100/entry_price)-100, 6))\n",
    "        long_drawdown_lst.append(round((min_low*100/entry_price)-100, 6))\n",
    "        short_runup_lst.append(round((entry_price*100/min_low)-100, 6))\n",
    "        short_drawdown_lst.append(round((entry_price*100/max_high)-100, 6))\n",
    "    else:\n",
    "        long_runup_lst.append(0)\n",
    "        long_drawdown_lst.append(0)\n",
    "        short_runup_lst.append(0)\n",
    "        short_drawdown_lst.append(0)     \n",
    "\n",
    "\n",
    "long=[]\n",
    "short=[]\n",
    "dont_trade=[]\n",
    "signal = []\n",
    "\n",
    "for idx in range(tot):\n",
    "    if (idx >= candlestick_frame) and (idx <= tot - candlestick_frame):\n",
    "        if long_runup_lst[idx] >= pnl_threshold:\n",
    "            signal.append(1)\n",
    "        elif short_runup_lst[idx] >= pnl_threshold:\n",
    "            signal.append(2)\n",
    "        else:\n",
    "            signal.append(0)\n",
    "    else:\n",
    "        signal.append(0)\n",
    "\n",
    "\n",
    "pc = [0] + [round((open[i]*100/open[(i-1)])-100, 4) for i in range(1,len(open), 1)]\n",
    "df = pd.DataFrame()\n",
    "df['0'] = pc\n",
    "y = pd.Series( (i for i in signal) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../data/df.csv', index=False)\n",
    "y.to_csv('../../data/y.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"id\"] = df.index\n",
    "df = df.melt(id_vars=\"id\", var_name=\"time\").sort_values([\"id\", \"time\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id time  value\n",
       "0   0    0    0.0\n",
       "1   1    0    0.0\n",
       "2   2    0    0.0\n",
       "3   3    0    0.0\n",
       "4   4    0    0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value__variance_larger_than_standard_deviation</th>\n",
       "      <th>value__has_duplicate_max</th>\n",
       "      <th>value__has_duplicate_min</th>\n",
       "      <th>value__has_duplicate</th>\n",
       "      <th>value__sum_values</th>\n",
       "      <th>value__abs_energy</th>\n",
       "      <th>value__mean_abs_change</th>\n",
       "      <th>value__mean_change</th>\n",
       "      <th>value__mean_second_derivative_central</th>\n",
       "      <th>value__median</th>\n",
       "      <th>...</th>\n",
       "      <th>value__fourier_entropy__bins_5</th>\n",
       "      <th>value__fourier_entropy__bins_10</th>\n",
       "      <th>value__fourier_entropy__bins_100</th>\n",
       "      <th>value__permutation_entropy__dimension_3__tau_1</th>\n",
       "      <th>value__permutation_entropy__dimension_4__tau_1</th>\n",
       "      <th>value__permutation_entropy__dimension_5__tau_1</th>\n",
       "      <th>value__permutation_entropy__dimension_6__tau_1</th>\n",
       "      <th>value__permutation_entropy__dimension_7__tau_1</th>\n",
       "      <th>value__query_similarity_count__query_None__threshold_0.0</th>\n",
       "      <th>value__mean_n_absolute_max__number_of_maxima_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   value__variance_larger_than_standard_deviation  value__has_duplicate_max  \\\n",
       "0                                             0.0                       0.0   \n",
       "1                                             0.0                       0.0   \n",
       "2                                             0.0                       0.0   \n",
       "3                                             0.0                       0.0   \n",
       "4                                             0.0                       0.0   \n",
       "\n",
       "   value__has_duplicate_min  value__has_duplicate  value__sum_values  \\\n",
       "0                       0.0                   0.0                0.0   \n",
       "1                       0.0                   0.0                0.0   \n",
       "2                       0.0                   0.0                0.0   \n",
       "3                       0.0                   0.0                0.0   \n",
       "4                       0.0                   0.0                0.0   \n",
       "\n",
       "   value__abs_energy  value__mean_abs_change  value__mean_change  \\\n",
       "0                0.0                     0.0                 0.0   \n",
       "1                0.0                     0.0                 0.0   \n",
       "2                0.0                     0.0                 0.0   \n",
       "3                0.0                     0.0                 0.0   \n",
       "4                0.0                     0.0                 0.0   \n",
       "\n",
       "   value__mean_second_derivative_central  value__median  ...  \\\n",
       "0                                    0.0            0.0  ...   \n",
       "1                                    0.0            0.0  ...   \n",
       "2                                    0.0            0.0  ...   \n",
       "3                                    0.0            0.0  ...   \n",
       "4                                    0.0            0.0  ...   \n",
       "\n",
       "   value__fourier_entropy__bins_5  value__fourier_entropy__bins_10  \\\n",
       "0                             0.0                              0.0   \n",
       "1                             0.0                              0.0   \n",
       "2                             0.0                              0.0   \n",
       "3                             0.0                              0.0   \n",
       "4                             0.0                              0.0   \n",
       "\n",
       "   value__fourier_entropy__bins_100  \\\n",
       "0                               0.0   \n",
       "1                               0.0   \n",
       "2                               0.0   \n",
       "3                               0.0   \n",
       "4                               0.0   \n",
       "\n",
       "   value__permutation_entropy__dimension_3__tau_1  \\\n",
       "0                                             0.0   \n",
       "1                                             0.0   \n",
       "2                                             0.0   \n",
       "3                                             0.0   \n",
       "4                                             0.0   \n",
       "\n",
       "   value__permutation_entropy__dimension_4__tau_1  \\\n",
       "0                                             0.0   \n",
       "1                                             0.0   \n",
       "2                                             0.0   \n",
       "3                                             0.0   \n",
       "4                                             0.0   \n",
       "\n",
       "   value__permutation_entropy__dimension_5__tau_1  \\\n",
       "0                                             0.0   \n",
       "1                                             0.0   \n",
       "2                                             0.0   \n",
       "3                                             0.0   \n",
       "4                                             0.0   \n",
       "\n",
       "   value__permutation_entropy__dimension_6__tau_1  \\\n",
       "0                                             0.0   \n",
       "1                                             0.0   \n",
       "2                                             0.0   \n",
       "3                                             0.0   \n",
       "4                                             0.0   \n",
       "\n",
       "   value__permutation_entropy__dimension_7__tau_1  \\\n",
       "0                                             0.0   \n",
       "1                                             0.0   \n",
       "2                                             0.0   \n",
       "3                                             0.0   \n",
       "4                                             0.0   \n",
       "\n",
       "   value__query_similarity_count__query_None__threshold_0.0  \\\n",
       "0                                                0.0          \n",
       "1                                                0.0          \n",
       "2                                                0.0          \n",
       "3                                                0.0          \n",
       "4                                                0.0          \n",
       "\n",
       "   value__mean_n_absolute_max__number_of_maxima_7  \n",
       "0                                             0.0  \n",
       "1                                             0.0  \n",
       "2                                             0.0  \n",
       "3                                             0.0  \n",
       "4                                             0.0  \n",
       "\n",
       "[5 rows x 783 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = extract_features(df[df[\"id\"] < len(df)], column_id=\"id\", column_sort=\"time\", impute_function=impute)\n",
    "X = pd.read_csv('../../data/X.csv')\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relevant features for class 0: 24/783\n",
      "Number of relevant features for class 1: 5/783\n",
      "Number of relevant features for class 2: 29/783\n"
     ]
    }
   ],
   "source": [
    "relevant_features = set()\n",
    "\n",
    "for label in y.unique():\n",
    "    y_train_binary = y_train == label\n",
    "    X_train_filtered = select_features(X_train, y_train_binary)\n",
    "    print(\"Number of relevant features for class {}: {}/{}\".format(label, X_train_filtered.shape[1], X_train.shape[1]))\n",
    "    relevant_features = relevant_features.union(set(X_train_filtered.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relevant_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filtered = X_train[list(relevant_features)]\n",
    "X_test_filtered = X_test[list(relevant_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value__range_count__max_1__min_-1</th>\n",
       "      <th>value__cwt_coefficients__coeff_0__w_20__widths_(2, 5, 10, 20)</th>\n",
       "      <th>value__quantile__q_0.8</th>\n",
       "      <th>value__sum_values</th>\n",
       "      <th>value__quantile__q_0.6</th>\n",
       "      <th>value__count_above__t_0</th>\n",
       "      <th>value__cwt_coefficients__coeff_0__w_10__widths_(2, 5, 10, 20)</th>\n",
       "      <th>value__quantile__q_0.9</th>\n",
       "      <th>value__quantile__q_0.4</th>\n",
       "      <th>value__mean</th>\n",
       "      <th>...</th>\n",
       "      <th>value__absolute_maximum</th>\n",
       "      <th>value__quantile__q_0.1</th>\n",
       "      <th>value__quantile__q_0.2</th>\n",
       "      <th>value__cwt_coefficients__coeff_0__w_2__widths_(2, 5, 10, 20)</th>\n",
       "      <th>value__cwt_coefficients__coeff_0__w_5__widths_(2, 5, 10, 20)</th>\n",
       "      <th>value__quantile__q_0.3</th>\n",
       "      <th>value__quantile__q_0.7</th>\n",
       "      <th>value__fft_coefficient__attr_\"real\"__coeff_0</th>\n",
       "      <th>value__count_below__t_0</th>\n",
       "      <th>value__minimum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.056495</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.079896</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2913</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>-0.178652</td>\n",
       "      <td>-0.112989</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.2913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3404</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011792</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016676</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.037288</td>\n",
       "      <td>0.023583</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77162</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033842</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.047861</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.107019</td>\n",
       "      <td>0.067685</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18427</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.127496</td>\n",
       "      <td>-0.6574</td>\n",
       "      <td>-0.6574</td>\n",
       "      <td>-0.6574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.180307</td>\n",
       "      <td>-0.6574</td>\n",
       "      <td>-0.6574</td>\n",
       "      <td>-0.6574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6574</td>\n",
       "      <td>-0.6574</td>\n",
       "      <td>-0.6574</td>\n",
       "      <td>-0.403178</td>\n",
       "      <td>-0.254992</td>\n",
       "      <td>-0.6574</td>\n",
       "      <td>-0.6574</td>\n",
       "      <td>-0.6574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.6574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27603</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014429</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020406</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.045629</td>\n",
       "      <td>0.028858</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40960</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.018987</td>\n",
       "      <td>-0.0979</td>\n",
       "      <td>-0.0979</td>\n",
       "      <td>-0.0979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.026851</td>\n",
       "      <td>-0.0979</td>\n",
       "      <td>-0.0979</td>\n",
       "      <td>-0.0979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>-0.0979</td>\n",
       "      <td>-0.0979</td>\n",
       "      <td>-0.060041</td>\n",
       "      <td>-0.037973</td>\n",
       "      <td>-0.0979</td>\n",
       "      <td>-0.0979</td>\n",
       "      <td>-0.0979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37989</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007734</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.017295</td>\n",
       "      <td>0.010938</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26590</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.718431</td>\n",
       "      <td>-3.7044</td>\n",
       "      <td>-3.7044</td>\n",
       "      <td>-3.7044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.016014</td>\n",
       "      <td>-3.7044</td>\n",
       "      <td>-3.7044</td>\n",
       "      <td>-3.7044</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7044</td>\n",
       "      <td>-3.7044</td>\n",
       "      <td>-3.7044</td>\n",
       "      <td>-2.271877</td>\n",
       "      <td>-1.436861</td>\n",
       "      <td>-3.7044</td>\n",
       "      <td>-3.7044</td>\n",
       "      <td>-3.7044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.7044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35322</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.068519</td>\n",
       "      <td>0.3533</td>\n",
       "      <td>0.3533</td>\n",
       "      <td>0.3533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.096900</td>\n",
       "      <td>0.3533</td>\n",
       "      <td>0.3533</td>\n",
       "      <td>0.3533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3533</td>\n",
       "      <td>0.3533</td>\n",
       "      <td>0.3533</td>\n",
       "      <td>0.216676</td>\n",
       "      <td>0.137038</td>\n",
       "      <td>0.3533</td>\n",
       "      <td>0.3533</td>\n",
       "      <td>0.3533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19391</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.007699</td>\n",
       "      <td>-0.0397</td>\n",
       "      <td>-0.0397</td>\n",
       "      <td>-0.0397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010889</td>\n",
       "      <td>-0.0397</td>\n",
       "      <td>-0.0397</td>\n",
       "      <td>-0.0397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>-0.0397</td>\n",
       "      <td>-0.0397</td>\n",
       "      <td>-0.024348</td>\n",
       "      <td>-0.015399</td>\n",
       "      <td>-0.0397</td>\n",
       "      <td>-0.0397</td>\n",
       "      <td>-0.0397</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92936 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       value__range_count__max_1__min_-1  \\\n",
       "2389                                 1.0   \n",
       "3404                                 1.0   \n",
       "77162                                1.0   \n",
       "18427                                1.0   \n",
       "27603                                1.0   \n",
       "...                                  ...   \n",
       "40960                                1.0   \n",
       "37989                                1.0   \n",
       "26590                                0.0   \n",
       "35322                                1.0   \n",
       "19391                                1.0   \n",
       "\n",
       "       value__cwt_coefficients__coeff_0__w_20__widths_(2, 5, 10, 20)  \\\n",
       "2389                                           -0.056495               \n",
       "3404                                            0.011792               \n",
       "77162                                           0.033842               \n",
       "18427                                          -0.127496               \n",
       "27603                                           0.014429               \n",
       "...                                                  ...               \n",
       "40960                                          -0.018987               \n",
       "37989                                           0.005469               \n",
       "26590                                          -0.718431               \n",
       "35322                                           0.068519               \n",
       "19391                                          -0.007699               \n",
       "\n",
       "       value__quantile__q_0.8  value__sum_values  value__quantile__q_0.6  \\\n",
       "2389                  -0.2913            -0.2913                 -0.2913   \n",
       "3404                   0.0608             0.0608                  0.0608   \n",
       "77162                  0.1745             0.1745                  0.1745   \n",
       "18427                 -0.6574            -0.6574                 -0.6574   \n",
       "27603                  0.0744             0.0744                  0.0744   \n",
       "...                       ...                ...                     ...   \n",
       "40960                 -0.0979            -0.0979                 -0.0979   \n",
       "37989                  0.0282             0.0282                  0.0282   \n",
       "26590                 -3.7044            -3.7044                 -3.7044   \n",
       "35322                  0.3533             0.3533                  0.3533   \n",
       "19391                 -0.0397            -0.0397                 -0.0397   \n",
       "\n",
       "       value__count_above__t_0  \\\n",
       "2389                       0.0   \n",
       "3404                       1.0   \n",
       "77162                      1.0   \n",
       "18427                      0.0   \n",
       "27603                      1.0   \n",
       "...                        ...   \n",
       "40960                      0.0   \n",
       "37989                      1.0   \n",
       "26590                      0.0   \n",
       "35322                      1.0   \n",
       "19391                      0.0   \n",
       "\n",
       "       value__cwt_coefficients__coeff_0__w_10__widths_(2, 5, 10, 20)  \\\n",
       "2389                                           -0.079896               \n",
       "3404                                            0.016676               \n",
       "77162                                           0.047861               \n",
       "18427                                          -0.180307               \n",
       "27603                                           0.020406               \n",
       "...                                                  ...               \n",
       "40960                                          -0.026851               \n",
       "37989                                           0.007734               \n",
       "26590                                          -1.016014               \n",
       "35322                                           0.096900               \n",
       "19391                                          -0.010889               \n",
       "\n",
       "       value__quantile__q_0.9  value__quantile__q_0.4  value__mean  ...  \\\n",
       "2389                  -0.2913                 -0.2913      -0.2913  ...   \n",
       "3404                   0.0608                  0.0608       0.0608  ...   \n",
       "77162                  0.1745                  0.1745       0.1745  ...   \n",
       "18427                 -0.6574                 -0.6574      -0.6574  ...   \n",
       "27603                  0.0744                  0.0744       0.0744  ...   \n",
       "...                       ...                     ...          ...  ...   \n",
       "40960                 -0.0979                 -0.0979      -0.0979  ...   \n",
       "37989                  0.0282                  0.0282       0.0282  ...   \n",
       "26590                 -3.7044                 -3.7044      -3.7044  ...   \n",
       "35322                  0.3533                  0.3533       0.3533  ...   \n",
       "19391                 -0.0397                 -0.0397      -0.0397  ...   \n",
       "\n",
       "       value__absolute_maximum  value__quantile__q_0.1  \\\n",
       "2389                    0.2913                 -0.2913   \n",
       "3404                    0.0608                  0.0608   \n",
       "77162                   0.1745                  0.1745   \n",
       "18427                   0.6574                 -0.6574   \n",
       "27603                   0.0744                  0.0744   \n",
       "...                        ...                     ...   \n",
       "40960                   0.0979                 -0.0979   \n",
       "37989                   0.0282                  0.0282   \n",
       "26590                   3.7044                 -3.7044   \n",
       "35322                   0.3533                  0.3533   \n",
       "19391                   0.0397                 -0.0397   \n",
       "\n",
       "       value__quantile__q_0.2  \\\n",
       "2389                  -0.2913   \n",
       "3404                   0.0608   \n",
       "77162                  0.1745   \n",
       "18427                 -0.6574   \n",
       "27603                  0.0744   \n",
       "...                       ...   \n",
       "40960                 -0.0979   \n",
       "37989                  0.0282   \n",
       "26590                 -3.7044   \n",
       "35322                  0.3533   \n",
       "19391                 -0.0397   \n",
       "\n",
       "       value__cwt_coefficients__coeff_0__w_2__widths_(2, 5, 10, 20)  \\\n",
       "2389                                           -0.178652              \n",
       "3404                                            0.037288              \n",
       "77162                                           0.107019              \n",
       "18427                                          -0.403178              \n",
       "27603                                           0.045629              \n",
       "...                                                  ...              \n",
       "40960                                          -0.060041              \n",
       "37989                                           0.017295              \n",
       "26590                                          -2.271877              \n",
       "35322                                           0.216676              \n",
       "19391                                          -0.024348              \n",
       "\n",
       "       value__cwt_coefficients__coeff_0__w_5__widths_(2, 5, 10, 20)  \\\n",
       "2389                                           -0.112989              \n",
       "3404                                            0.023583              \n",
       "77162                                           0.067685              \n",
       "18427                                          -0.254992              \n",
       "27603                                           0.028858              \n",
       "...                                                  ...              \n",
       "40960                                          -0.037973              \n",
       "37989                                           0.010938              \n",
       "26590                                          -1.436861              \n",
       "35322                                           0.137038              \n",
       "19391                                          -0.015399              \n",
       "\n",
       "       value__quantile__q_0.3  value__quantile__q_0.7  \\\n",
       "2389                  -0.2913                 -0.2913   \n",
       "3404                   0.0608                  0.0608   \n",
       "77162                  0.1745                  0.1745   \n",
       "18427                 -0.6574                 -0.6574   \n",
       "27603                  0.0744                  0.0744   \n",
       "...                       ...                     ...   \n",
       "40960                 -0.0979                 -0.0979   \n",
       "37989                  0.0282                  0.0282   \n",
       "26590                 -3.7044                 -3.7044   \n",
       "35322                  0.3533                  0.3533   \n",
       "19391                 -0.0397                 -0.0397   \n",
       "\n",
       "       value__fft_coefficient__attr_\"real\"__coeff_0  value__count_below__t_0  \\\n",
       "2389                                        -0.2913                      1.0   \n",
       "3404                                         0.0608                      0.0   \n",
       "77162                                        0.1745                      0.0   \n",
       "18427                                       -0.6574                      1.0   \n",
       "27603                                        0.0744                      0.0   \n",
       "...                                             ...                      ...   \n",
       "40960                                       -0.0979                      1.0   \n",
       "37989                                        0.0282                      0.0   \n",
       "26590                                       -3.7044                      1.0   \n",
       "35322                                        0.3533                      0.0   \n",
       "19391                                       -0.0397                      1.0   \n",
       "\n",
       "       value__minimum  \n",
       "2389          -0.2913  \n",
       "3404           0.0608  \n",
       "77162          0.1745  \n",
       "18427         -0.6574  \n",
       "27603          0.0744  \n",
       "...               ...  \n",
       "40960         -0.0979  \n",
       "37989          0.0282  \n",
       "26590         -3.7044  \n",
       "35322          0.3533  \n",
       "19391         -0.0397  \n",
       "\n",
       "[92936 rows x 29 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y) == (len(X_train_filtered) + len(X_test_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [X_train_filtered, X_test_filtered]\n",
    "concatenated_df = pd.concat(dfs, ignore_index=True)  # Set ignore_index=True to reset index\n",
    "concatenated_df['signal'] = y\n",
    "pd.DataFrame(concatenated_df).to_csv(f'../../data/training_dataset_pc_tsfresh.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value__range_count__max_1__min_-1</th>\n",
       "      <th>value__cwt_coefficients__coeff_0__w_20__widths_(2, 5, 10, 20)</th>\n",
       "      <th>value__quantile__q_0.8</th>\n",
       "      <th>value__sum_values</th>\n",
       "      <th>value__quantile__q_0.6</th>\n",
       "      <th>value__count_above__t_0</th>\n",
       "      <th>value__cwt_coefficients__coeff_0__w_10__widths_(2, 5, 10, 20)</th>\n",
       "      <th>value__quantile__q_0.9</th>\n",
       "      <th>value__quantile__q_0.4</th>\n",
       "      <th>value__mean</th>\n",
       "      <th>...</th>\n",
       "      <th>value__quantile__q_0.1</th>\n",
       "      <th>value__quantile__q_0.2</th>\n",
       "      <th>value__cwt_coefficients__coeff_0__w_2__widths_(2, 5, 10, 20)</th>\n",
       "      <th>value__cwt_coefficients__coeff_0__w_5__widths_(2, 5, 10, 20)</th>\n",
       "      <th>value__quantile__q_0.3</th>\n",
       "      <th>value__quantile__q_0.7</th>\n",
       "      <th>value__fft_coefficient__attr_\"real\"__coeff_0</th>\n",
       "      <th>value__count_below__t_0</th>\n",
       "      <th>value__minimum</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.056495</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.079896</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>-0.178652</td>\n",
       "      <td>-0.112989</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011792</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016676</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.037288</td>\n",
       "      <td>0.023583</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033842</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.047861</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.107019</td>\n",
       "      <td>0.067685</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.127496</td>\n",
       "      <td>-0.6574</td>\n",
       "      <td>-0.6574</td>\n",
       "      <td>-0.6574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.180307</td>\n",
       "      <td>-0.6574</td>\n",
       "      <td>-0.6574</td>\n",
       "      <td>-0.6574</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.6574</td>\n",
       "      <td>-0.6574</td>\n",
       "      <td>-0.403178</td>\n",
       "      <td>-0.254992</td>\n",
       "      <td>-0.6574</td>\n",
       "      <td>-0.6574</td>\n",
       "      <td>-0.6574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.6574</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014429</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020406</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.045629</td>\n",
       "      <td>0.028858</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116166</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.035142</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.049698</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.111128</td>\n",
       "      <td>0.070284</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116167</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.106744</td>\n",
       "      <td>0.5504</td>\n",
       "      <td>0.5504</td>\n",
       "      <td>0.5504</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.150959</td>\n",
       "      <td>0.5504</td>\n",
       "      <td>0.5504</td>\n",
       "      <td>0.5504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5504</td>\n",
       "      <td>0.5504</td>\n",
       "      <td>0.337556</td>\n",
       "      <td>0.213489</td>\n",
       "      <td>0.5504</td>\n",
       "      <td>0.5504</td>\n",
       "      <td>0.5504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5504</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116168</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033461</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.074822</td>\n",
       "      <td>0.047321</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116169</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015457</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021859</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>0.048879</td>\n",
       "      <td>0.030914</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116170</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.003762</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.005321</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>-0.011898</td>\n",
       "      <td>-0.007525</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116171 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        value__range_count__max_1__min_-1  \\\n",
       "0                                     1.0   \n",
       "1                                     1.0   \n",
       "2                                     1.0   \n",
       "3                                     1.0   \n",
       "4                                     1.0   \n",
       "...                                   ...   \n",
       "116166                                1.0   \n",
       "116167                                1.0   \n",
       "116168                                1.0   \n",
       "116169                                1.0   \n",
       "116170                                1.0   \n",
       "\n",
       "        value__cwt_coefficients__coeff_0__w_20__widths_(2, 5, 10, 20)  \\\n",
       "0                                               -0.056495               \n",
       "1                                                0.011792               \n",
       "2                                                0.033842               \n",
       "3                                               -0.127496               \n",
       "4                                                0.014429               \n",
       "...                                                   ...               \n",
       "116166                                           0.035142               \n",
       "116167                                           0.106744               \n",
       "116168                                           0.023661               \n",
       "116169                                           0.015457               \n",
       "116170                                          -0.003762               \n",
       "\n",
       "        value__quantile__q_0.8  value__sum_values  value__quantile__q_0.6  \\\n",
       "0                      -0.2913            -0.2913                 -0.2913   \n",
       "1                       0.0608             0.0608                  0.0608   \n",
       "2                       0.1745             0.1745                  0.1745   \n",
       "3                      -0.6574            -0.6574                 -0.6574   \n",
       "4                       0.0744             0.0744                  0.0744   \n",
       "...                        ...                ...                     ...   \n",
       "116166                  0.1812             0.1812                  0.1812   \n",
       "116167                  0.5504             0.5504                  0.5504   \n",
       "116168                  0.1220             0.1220                  0.1220   \n",
       "116169                  0.0797             0.0797                  0.0797   \n",
       "116170                 -0.0194            -0.0194                 -0.0194   \n",
       "\n",
       "        value__count_above__t_0  \\\n",
       "0                           0.0   \n",
       "1                           1.0   \n",
       "2                           1.0   \n",
       "3                           0.0   \n",
       "4                           1.0   \n",
       "...                         ...   \n",
       "116166                      1.0   \n",
       "116167                      1.0   \n",
       "116168                      1.0   \n",
       "116169                      1.0   \n",
       "116170                      0.0   \n",
       "\n",
       "        value__cwt_coefficients__coeff_0__w_10__widths_(2, 5, 10, 20)  \\\n",
       "0                                               -0.079896               \n",
       "1                                                0.016676               \n",
       "2                                                0.047861               \n",
       "3                                               -0.180307               \n",
       "4                                                0.020406               \n",
       "...                                                   ...               \n",
       "116166                                           0.049698               \n",
       "116167                                           0.150959               \n",
       "116168                                           0.033461               \n",
       "116169                                           0.021859               \n",
       "116170                                          -0.005321               \n",
       "\n",
       "        value__quantile__q_0.9  value__quantile__q_0.4  value__mean  ...  \\\n",
       "0                      -0.2913                 -0.2913      -0.2913  ...   \n",
       "1                       0.0608                  0.0608       0.0608  ...   \n",
       "2                       0.1745                  0.1745       0.1745  ...   \n",
       "3                      -0.6574                 -0.6574      -0.6574  ...   \n",
       "4                       0.0744                  0.0744       0.0744  ...   \n",
       "...                        ...                     ...          ...  ...   \n",
       "116166                  0.1812                  0.1812       0.1812  ...   \n",
       "116167                  0.5504                  0.5504       0.5504  ...   \n",
       "116168                  0.1220                  0.1220       0.1220  ...   \n",
       "116169                  0.0797                  0.0797       0.0797  ...   \n",
       "116170                 -0.0194                 -0.0194      -0.0194  ...   \n",
       "\n",
       "        value__quantile__q_0.1  value__quantile__q_0.2  \\\n",
       "0                      -0.2913                 -0.2913   \n",
       "1                       0.0608                  0.0608   \n",
       "2                       0.1745                  0.1745   \n",
       "3                      -0.6574                 -0.6574   \n",
       "4                       0.0744                  0.0744   \n",
       "...                        ...                     ...   \n",
       "116166                  0.1812                  0.1812   \n",
       "116167                  0.5504                  0.5504   \n",
       "116168                  0.1220                  0.1220   \n",
       "116169                  0.0797                  0.0797   \n",
       "116170                 -0.0194                 -0.0194   \n",
       "\n",
       "        value__cwt_coefficients__coeff_0__w_2__widths_(2, 5, 10, 20)  \\\n",
       "0                                               -0.178652              \n",
       "1                                                0.037288              \n",
       "2                                                0.107019              \n",
       "3                                               -0.403178              \n",
       "4                                                0.045629              \n",
       "...                                                   ...              \n",
       "116166                                           0.111128              \n",
       "116167                                           0.337556              \n",
       "116168                                           0.074822              \n",
       "116169                                           0.048879              \n",
       "116170                                          -0.011898              \n",
       "\n",
       "        value__cwt_coefficients__coeff_0__w_5__widths_(2, 5, 10, 20)  \\\n",
       "0                                               -0.112989              \n",
       "1                                                0.023583              \n",
       "2                                                0.067685              \n",
       "3                                               -0.254992              \n",
       "4                                                0.028858              \n",
       "...                                                   ...              \n",
       "116166                                           0.070284              \n",
       "116167                                           0.213489              \n",
       "116168                                           0.047321              \n",
       "116169                                           0.030914              \n",
       "116170                                          -0.007525              \n",
       "\n",
       "        value__quantile__q_0.3  value__quantile__q_0.7  \\\n",
       "0                      -0.2913                 -0.2913   \n",
       "1                       0.0608                  0.0608   \n",
       "2                       0.1745                  0.1745   \n",
       "3                      -0.6574                 -0.6574   \n",
       "4                       0.0744                  0.0744   \n",
       "...                        ...                     ...   \n",
       "116166                  0.1812                  0.1812   \n",
       "116167                  0.5504                  0.5504   \n",
       "116168                  0.1220                  0.1220   \n",
       "116169                  0.0797                  0.0797   \n",
       "116170                 -0.0194                 -0.0194   \n",
       "\n",
       "        value__fft_coefficient__attr_\"real\"__coeff_0  value__count_below__t_0  \\\n",
       "0                                            -0.2913                      1.0   \n",
       "1                                             0.0608                      0.0   \n",
       "2                                             0.1745                      0.0   \n",
       "3                                            -0.6574                      1.0   \n",
       "4                                             0.0744                      0.0   \n",
       "...                                              ...                      ...   \n",
       "116166                                        0.1812                      0.0   \n",
       "116167                                        0.5504                      0.0   \n",
       "116168                                        0.1220                      0.0   \n",
       "116169                                        0.0797                      0.0   \n",
       "116170                                       -0.0194                      1.0   \n",
       "\n",
       "        value__minimum  signal  \n",
       "0              -0.2913       0  \n",
       "1               0.0608       0  \n",
       "2               0.1745       0  \n",
       "3              -0.6574       0  \n",
       "4               0.0744       0  \n",
       "...                ...     ...  \n",
       "116166          0.1812       0  \n",
       "116167          0.5504       0  \n",
       "116168          0.1220       0  \n",
       "116169          0.0797       0  \n",
       "116170         -0.0194       0  \n",
       "\n",
       "[116171 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "\n",
    "concatenated_df = pd.read_csv('../../data/training_dataset_pc_tsfresh.csv')\n",
    "\n",
    "\n",
    "X = concatenated_df.drop('signal', axis=1)\n",
    "y = concatenated_df['signal']\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Fit and resample the data\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X_resampled\n",
    "data['signal'] = list(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value__range_count__max_1__min_-1</th>\n",
       "      <th>value__cwt_coefficients__coeff_0__w_20__widths_(2, 5, 10, 20)</th>\n",
       "      <th>value__quantile__q_0.8</th>\n",
       "      <th>value__sum_values</th>\n",
       "      <th>value__quantile__q_0.6</th>\n",
       "      <th>value__count_above__t_0</th>\n",
       "      <th>value__cwt_coefficients__coeff_0__w_10__widths_(2, 5, 10, 20)</th>\n",
       "      <th>value__quantile__q_0.9</th>\n",
       "      <th>value__quantile__q_0.4</th>\n",
       "      <th>value__mean</th>\n",
       "      <th>...</th>\n",
       "      <th>value__quantile__q_0.1</th>\n",
       "      <th>value__quantile__q_0.2</th>\n",
       "      <th>value__cwt_coefficients__coeff_0__w_2__widths_(2, 5, 10, 20)</th>\n",
       "      <th>value__cwt_coefficients__coeff_0__w_5__widths_(2, 5, 10, 20)</th>\n",
       "      <th>value__quantile__q_0.3</th>\n",
       "      <th>value__quantile__q_0.7</th>\n",
       "      <th>value__fft_coefficient__attr_\"real\"__coeff_0</th>\n",
       "      <th>value__count_below__t_0</th>\n",
       "      <th>value__minimum</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.056495</td>\n",
       "      <td>-0.291300</td>\n",
       "      <td>-0.291300</td>\n",
       "      <td>-0.291300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.079896</td>\n",
       "      <td>-0.291300</td>\n",
       "      <td>-0.291300</td>\n",
       "      <td>-0.291300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.291300</td>\n",
       "      <td>-0.291300</td>\n",
       "      <td>-0.178652</td>\n",
       "      <td>-0.112989</td>\n",
       "      <td>-0.291300</td>\n",
       "      <td>-0.291300</td>\n",
       "      <td>-0.291300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.291300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011792</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016676</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0.037288</td>\n",
       "      <td>0.023583</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033842</td>\n",
       "      <td>0.174500</td>\n",
       "      <td>0.174500</td>\n",
       "      <td>0.174500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.047861</td>\n",
       "      <td>0.174500</td>\n",
       "      <td>0.174500</td>\n",
       "      <td>0.174500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174500</td>\n",
       "      <td>0.174500</td>\n",
       "      <td>0.107019</td>\n",
       "      <td>0.067685</td>\n",
       "      <td>0.174500</td>\n",
       "      <td>0.174500</td>\n",
       "      <td>0.174500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.174500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.127496</td>\n",
       "      <td>-0.657400</td>\n",
       "      <td>-0.657400</td>\n",
       "      <td>-0.657400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.180307</td>\n",
       "      <td>-0.657400</td>\n",
       "      <td>-0.657400</td>\n",
       "      <td>-0.657400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.657400</td>\n",
       "      <td>-0.657400</td>\n",
       "      <td>-0.403178</td>\n",
       "      <td>-0.254992</td>\n",
       "      <td>-0.657400</td>\n",
       "      <td>-0.657400</td>\n",
       "      <td>-0.657400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.657400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014429</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020406</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.045629</td>\n",
       "      <td>0.028858</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331585</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.078984</td>\n",
       "      <td>0.407259</td>\n",
       "      <td>0.407259</td>\n",
       "      <td>0.407259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111700</td>\n",
       "      <td>0.407259</td>\n",
       "      <td>0.407259</td>\n",
       "      <td>0.407259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407259</td>\n",
       "      <td>0.407259</td>\n",
       "      <td>0.249768</td>\n",
       "      <td>0.157967</td>\n",
       "      <td>0.407259</td>\n",
       "      <td>0.407259</td>\n",
       "      <td>0.407259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.407259</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331586</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.063113</td>\n",
       "      <td>0.325428</td>\n",
       "      <td>0.325428</td>\n",
       "      <td>0.325428</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.089256</td>\n",
       "      <td>0.325428</td>\n",
       "      <td>0.325428</td>\n",
       "      <td>0.325428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325428</td>\n",
       "      <td>0.325428</td>\n",
       "      <td>0.199582</td>\n",
       "      <td>0.126227</td>\n",
       "      <td>0.325428</td>\n",
       "      <td>0.325428</td>\n",
       "      <td>0.325428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325428</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331587</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.108324</td>\n",
       "      <td>-0.558542</td>\n",
       "      <td>-0.558542</td>\n",
       "      <td>-0.558542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.153193</td>\n",
       "      <td>-0.558542</td>\n",
       "      <td>-0.558542</td>\n",
       "      <td>-0.558542</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.558542</td>\n",
       "      <td>-0.558542</td>\n",
       "      <td>-0.342549</td>\n",
       "      <td>-0.216647</td>\n",
       "      <td>-0.558542</td>\n",
       "      <td>-0.558542</td>\n",
       "      <td>-0.558542</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.558542</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331588</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.012005</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016977</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.037963</td>\n",
       "      <td>0.024010</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331589</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.003037</td>\n",
       "      <td>-0.015657</td>\n",
       "      <td>-0.015657</td>\n",
       "      <td>-0.015657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004294</td>\n",
       "      <td>-0.015657</td>\n",
       "      <td>-0.015657</td>\n",
       "      <td>-0.015657</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015657</td>\n",
       "      <td>-0.015657</td>\n",
       "      <td>-0.009602</td>\n",
       "      <td>-0.006073</td>\n",
       "      <td>-0.015657</td>\n",
       "      <td>-0.015657</td>\n",
       "      <td>-0.015657</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.015657</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331590 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        value__range_count__max_1__min_-1  \\\n",
       "0                                     1.0   \n",
       "1                                     1.0   \n",
       "2                                     1.0   \n",
       "3                                     1.0   \n",
       "4                                     1.0   \n",
       "...                                   ...   \n",
       "331585                                1.0   \n",
       "331586                                1.0   \n",
       "331587                                1.0   \n",
       "331588                                1.0   \n",
       "331589                                1.0   \n",
       "\n",
       "        value__cwt_coefficients__coeff_0__w_20__widths_(2, 5, 10, 20)  \\\n",
       "0                                               -0.056495               \n",
       "1                                                0.011792               \n",
       "2                                                0.033842               \n",
       "3                                               -0.127496               \n",
       "4                                                0.014429               \n",
       "...                                                   ...               \n",
       "331585                                           0.078984               \n",
       "331586                                           0.063113               \n",
       "331587                                          -0.108324               \n",
       "331588                                           0.012005               \n",
       "331589                                          -0.003037               \n",
       "\n",
       "        value__quantile__q_0.8  value__sum_values  value__quantile__q_0.6  \\\n",
       "0                    -0.291300          -0.291300               -0.291300   \n",
       "1                     0.060800           0.060800                0.060800   \n",
       "2                     0.174500           0.174500                0.174500   \n",
       "3                    -0.657400          -0.657400               -0.657400   \n",
       "4                     0.074400           0.074400                0.074400   \n",
       "...                        ...                ...                     ...   \n",
       "331585                0.407259           0.407259                0.407259   \n",
       "331586                0.325428           0.325428                0.325428   \n",
       "331587               -0.558542          -0.558542               -0.558542   \n",
       "331588                0.061900           0.061900                0.061900   \n",
       "331589               -0.015657          -0.015657               -0.015657   \n",
       "\n",
       "        value__count_above__t_0  \\\n",
       "0                           0.0   \n",
       "1                           1.0   \n",
       "2                           1.0   \n",
       "3                           0.0   \n",
       "4                           1.0   \n",
       "...                         ...   \n",
       "331585                      1.0   \n",
       "331586                      1.0   \n",
       "331587                      0.0   \n",
       "331588                      1.0   \n",
       "331589                      0.0   \n",
       "\n",
       "        value__cwt_coefficients__coeff_0__w_10__widths_(2, 5, 10, 20)  \\\n",
       "0                                               -0.079896               \n",
       "1                                                0.016676               \n",
       "2                                                0.047861               \n",
       "3                                               -0.180307               \n",
       "4                                                0.020406               \n",
       "...                                                   ...               \n",
       "331585                                           0.111700               \n",
       "331586                                           0.089256               \n",
       "331587                                          -0.153193               \n",
       "331588                                           0.016977               \n",
       "331589                                          -0.004294               \n",
       "\n",
       "        value__quantile__q_0.9  value__quantile__q_0.4  value__mean  ...  \\\n",
       "0                    -0.291300               -0.291300    -0.291300  ...   \n",
       "1                     0.060800                0.060800     0.060800  ...   \n",
       "2                     0.174500                0.174500     0.174500  ...   \n",
       "3                    -0.657400               -0.657400    -0.657400  ...   \n",
       "4                     0.074400                0.074400     0.074400  ...   \n",
       "...                        ...                     ...          ...  ...   \n",
       "331585                0.407259                0.407259     0.407259  ...   \n",
       "331586                0.325428                0.325428     0.325428  ...   \n",
       "331587               -0.558542               -0.558542    -0.558542  ...   \n",
       "331588                0.061900                0.061900     0.061900  ...   \n",
       "331589               -0.015657               -0.015657    -0.015657  ...   \n",
       "\n",
       "        value__quantile__q_0.1  value__quantile__q_0.2  \\\n",
       "0                    -0.291300               -0.291300   \n",
       "1                     0.060800                0.060800   \n",
       "2                     0.174500                0.174500   \n",
       "3                    -0.657400               -0.657400   \n",
       "4                     0.074400                0.074400   \n",
       "...                        ...                     ...   \n",
       "331585                0.407259                0.407259   \n",
       "331586                0.325428                0.325428   \n",
       "331587               -0.558542               -0.558542   \n",
       "331588                0.061900                0.061900   \n",
       "331589               -0.015657               -0.015657   \n",
       "\n",
       "        value__cwt_coefficients__coeff_0__w_2__widths_(2, 5, 10, 20)  \\\n",
       "0                                               -0.178652              \n",
       "1                                                0.037288              \n",
       "2                                                0.107019              \n",
       "3                                               -0.403178              \n",
       "4                                                0.045629              \n",
       "...                                                   ...              \n",
       "331585                                           0.249768              \n",
       "331586                                           0.199582              \n",
       "331587                                          -0.342549              \n",
       "331588                                           0.037963              \n",
       "331589                                          -0.009602              \n",
       "\n",
       "        value__cwt_coefficients__coeff_0__w_5__widths_(2, 5, 10, 20)  \\\n",
       "0                                               -0.112989              \n",
       "1                                                0.023583              \n",
       "2                                                0.067685              \n",
       "3                                               -0.254992              \n",
       "4                                                0.028858              \n",
       "...                                                   ...              \n",
       "331585                                           0.157967              \n",
       "331586                                           0.126227              \n",
       "331587                                          -0.216647              \n",
       "331588                                           0.024010              \n",
       "331589                                          -0.006073              \n",
       "\n",
       "        value__quantile__q_0.3  value__quantile__q_0.7  \\\n",
       "0                    -0.291300               -0.291300   \n",
       "1                     0.060800                0.060800   \n",
       "2                     0.174500                0.174500   \n",
       "3                    -0.657400               -0.657400   \n",
       "4                     0.074400                0.074400   \n",
       "...                        ...                     ...   \n",
       "331585                0.407259                0.407259   \n",
       "331586                0.325428                0.325428   \n",
       "331587               -0.558542               -0.558542   \n",
       "331588                0.061900                0.061900   \n",
       "331589               -0.015657               -0.015657   \n",
       "\n",
       "        value__fft_coefficient__attr_\"real\"__coeff_0  value__count_below__t_0  \\\n",
       "0                                          -0.291300                      1.0   \n",
       "1                                           0.060800                      0.0   \n",
       "2                                           0.174500                      0.0   \n",
       "3                                          -0.657400                      1.0   \n",
       "4                                           0.074400                      0.0   \n",
       "...                                              ...                      ...   \n",
       "331585                                      0.407259                      0.0   \n",
       "331586                                      0.325428                      0.0   \n",
       "331587                                     -0.558542                      1.0   \n",
       "331588                                      0.061900                      0.0   \n",
       "331589                                     -0.015657                      1.0   \n",
       "\n",
       "        value__minimum  signal  \n",
       "0            -0.291300       0  \n",
       "1             0.060800       0  \n",
       "2             0.174500       0  \n",
       "3            -0.657400       0  \n",
       "4             0.074400       0  \n",
       "...                ...     ...  \n",
       "331585        0.407259       2  \n",
       "331586        0.325428       2  \n",
       "331587       -0.558542       2  \n",
       "331588        0.061900       2  \n",
       "331589       -0.015657       2  \n",
       "\n",
       "[331590 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_CUDAP=1\n",
      "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_CUDAP=1\n",
      "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_CUDAP=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_CUDAP=1\n",
      "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_CUDAP=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_CUDAP=1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_579fa_row8_col1, #T_579fa_row15_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_579fa\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_579fa_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_579fa_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_579fa_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_579fa_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_579fa_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_579fa_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_579fa_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_579fa_row1_col1\" class=\"data row1 col1\" >signal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_579fa_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_579fa_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_579fa_row2_col1\" class=\"data row2 col1\" >Multiclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_579fa_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_579fa_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_579fa_row3_col1\" class=\"data row3 col1\" >(331590, 30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_579fa_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_579fa_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_579fa_row4_col1\" class=\"data row4 col1\" >(331590, 30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_579fa_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_579fa_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_579fa_row5_col1\" class=\"data row5 col1\" >(232112, 30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_579fa_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_579fa_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_579fa_row6_col1\" class=\"data row6 col1\" >(99478, 30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_579fa_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_579fa_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_579fa_row7_col1\" class=\"data row7 col1\" >29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_579fa_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_579fa_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_579fa_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_579fa_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_579fa_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_579fa_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_579fa_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_579fa_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_579fa_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_579fa_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_579fa_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_579fa_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_579fa_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_579fa_row12_col0\" class=\"data row12 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_579fa_row12_col1\" class=\"data row12 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_579fa_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_579fa_row13_col0\" class=\"data row13 col0\" >Fold Number</td>\n",
       "      <td id=\"T_579fa_row13_col1\" class=\"data row13 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_579fa_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_579fa_row14_col0\" class=\"data row14 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_579fa_row14_col1\" class=\"data row14 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_579fa_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_579fa_row15_col0\" class=\"data row15 col0\" >Use GPU</td>\n",
       "      <td id=\"T_579fa_row15_col1\" class=\"data row15 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_579fa_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_579fa_row16_col0\" class=\"data row16 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_579fa_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_579fa_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_579fa_row17_col0\" class=\"data row17 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_579fa_row17_col1\" class=\"data row17 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_579fa_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_579fa_row18_col0\" class=\"data row18 col0\" >USI</td>\n",
       "      <td id=\"T_579fa_row18_col1\" class=\"data row18 col1\" >7cc0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff7268eccd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_CUDAP=1\n",
      "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_CUDAP=1\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9418b th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9418b_row0_col0, #T_9418b_row0_col2, #T_9418b_row1_col0, #T_9418b_row1_col1, #T_9418b_row1_col2, #T_9418b_row1_col3, #T_9418b_row1_col4, #T_9418b_row1_col5, #T_9418b_row1_col6, #T_9418b_row1_col7, #T_9418b_row2_col0, #T_9418b_row2_col1, #T_9418b_row2_col3, #T_9418b_row2_col4, #T_9418b_row2_col5, #T_9418b_row2_col6, #T_9418b_row2_col7, #T_9418b_row3_col0, #T_9418b_row3_col1, #T_9418b_row3_col2, #T_9418b_row3_col3, #T_9418b_row3_col4, #T_9418b_row3_col5, #T_9418b_row3_col6, #T_9418b_row3_col7, #T_9418b_row4_col0, #T_9418b_row4_col1, #T_9418b_row4_col2, #T_9418b_row4_col3, #T_9418b_row4_col4, #T_9418b_row4_col5, #T_9418b_row4_col6, #T_9418b_row4_col7, #T_9418b_row5_col0, #T_9418b_row5_col1, #T_9418b_row5_col2, #T_9418b_row5_col3, #T_9418b_row5_col4, #T_9418b_row5_col5, #T_9418b_row5_col6, #T_9418b_row5_col7, #T_9418b_row6_col0, #T_9418b_row6_col1, #T_9418b_row6_col2, #T_9418b_row6_col3, #T_9418b_row6_col4, #T_9418b_row6_col5, #T_9418b_row6_col6, #T_9418b_row6_col7, #T_9418b_row7_col0, #T_9418b_row7_col1, #T_9418b_row7_col2, #T_9418b_row7_col3, #T_9418b_row7_col4, #T_9418b_row7_col5, #T_9418b_row7_col6, #T_9418b_row7_col7, #T_9418b_row8_col0, #T_9418b_row8_col1, #T_9418b_row8_col2, #T_9418b_row8_col3, #T_9418b_row8_col4, #T_9418b_row8_col5, #T_9418b_row8_col6, #T_9418b_row8_col7, #T_9418b_row9_col0, #T_9418b_row9_col1, #T_9418b_row9_col2, #T_9418b_row9_col3, #T_9418b_row9_col4, #T_9418b_row9_col5, #T_9418b_row9_col6, #T_9418b_row9_col7, #T_9418b_row10_col0, #T_9418b_row10_col1, #T_9418b_row10_col2, #T_9418b_row10_col3, #T_9418b_row10_col4, #T_9418b_row10_col5, #T_9418b_row10_col6, #T_9418b_row10_col7, #T_9418b_row11_col0, #T_9418b_row11_col1, #T_9418b_row11_col2, #T_9418b_row11_col3, #T_9418b_row11_col4, #T_9418b_row11_col5, #T_9418b_row11_col6, #T_9418b_row11_col7, #T_9418b_row12_col0, #T_9418b_row12_col1, #T_9418b_row12_col2, #T_9418b_row12_col3, #T_9418b_row12_col4, #T_9418b_row12_col5, #T_9418b_row12_col6, #T_9418b_row12_col7, #T_9418b_row13_col0, #T_9418b_row13_col1, #T_9418b_row13_col2, #T_9418b_row13_col3, #T_9418b_row13_col4, #T_9418b_row13_col5, #T_9418b_row13_col6, #T_9418b_row13_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9418b_row0_col1, #T_9418b_row0_col3, #T_9418b_row0_col4, #T_9418b_row0_col5, #T_9418b_row0_col6, #T_9418b_row0_col7, #T_9418b_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_9418b_row0_col8, #T_9418b_row1_col8, #T_9418b_row2_col8, #T_9418b_row3_col8, #T_9418b_row4_col8, #T_9418b_row5_col8, #T_9418b_row6_col8, #T_9418b_row7_col8, #T_9418b_row8_col8, #T_9418b_row9_col8, #T_9418b_row10_col8, #T_9418b_row11_col8, #T_9418b_row13_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_9418b_row12_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9418b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9418b_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_9418b_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_9418b_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_9418b_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_9418b_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_9418b_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_9418b_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_9418b_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_9418b_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9418b_level0_row0\" class=\"row_heading level0 row0\" >dt</th>\n",
       "      <td id=\"T_9418b_row0_col0\" class=\"data row0 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_9418b_row0_col1\" class=\"data row0 col1\" >0.6964</td>\n",
       "      <td id=\"T_9418b_row0_col2\" class=\"data row0 col2\" >0.7793</td>\n",
       "      <td id=\"T_9418b_row0_col3\" class=\"data row0 col3\" >0.6964</td>\n",
       "      <td id=\"T_9418b_row0_col4\" class=\"data row0 col4\" >0.6902</td>\n",
       "      <td id=\"T_9418b_row0_col5\" class=\"data row0 col5\" >0.6914</td>\n",
       "      <td id=\"T_9418b_row0_col6\" class=\"data row0 col6\" >0.5446</td>\n",
       "      <td id=\"T_9418b_row0_col7\" class=\"data row0 col7\" >0.5461</td>\n",
       "      <td id=\"T_9418b_row0_col8\" class=\"data row0 col8\" >0.3980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9418b_level0_row1\" class=\"row_heading level0 row1\" >et</th>\n",
       "      <td id=\"T_9418b_row1_col0\" class=\"data row1 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_9418b_row1_col1\" class=\"data row1 col1\" >0.6955</td>\n",
       "      <td id=\"T_9418b_row1_col2\" class=\"data row1 col2\" >0.8352</td>\n",
       "      <td id=\"T_9418b_row1_col3\" class=\"data row1 col3\" >0.6955</td>\n",
       "      <td id=\"T_9418b_row1_col4\" class=\"data row1 col4\" >0.6893</td>\n",
       "      <td id=\"T_9418b_row1_col5\" class=\"data row1 col5\" >0.6907</td>\n",
       "      <td id=\"T_9418b_row1_col6\" class=\"data row1 col6\" >0.5433</td>\n",
       "      <td id=\"T_9418b_row1_col7\" class=\"data row1 col7\" >0.5446</td>\n",
       "      <td id=\"T_9418b_row1_col8\" class=\"data row1 col8\" >25.5610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9418b_level0_row2\" class=\"row_heading level0 row2\" >rf</th>\n",
       "      <td id=\"T_9418b_row2_col0\" class=\"data row2 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_9418b_row2_col1\" class=\"data row2 col1\" >0.6939</td>\n",
       "      <td id=\"T_9418b_row2_col2\" class=\"data row2 col2\" >0.8432</td>\n",
       "      <td id=\"T_9418b_row2_col3\" class=\"data row2 col3\" >0.6939</td>\n",
       "      <td id=\"T_9418b_row2_col4\" class=\"data row2 col4\" >0.6879</td>\n",
       "      <td id=\"T_9418b_row2_col5\" class=\"data row2 col5\" >0.6893</td>\n",
       "      <td id=\"T_9418b_row2_col6\" class=\"data row2 col6\" >0.5408</td>\n",
       "      <td id=\"T_9418b_row2_col7\" class=\"data row2 col7\" >0.5420</td>\n",
       "      <td id=\"T_9418b_row2_col8\" class=\"data row2 col8\" >55.4980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9418b_level0_row3\" class=\"row_heading level0 row3\" >knn</th>\n",
       "      <td id=\"T_9418b_row3_col0\" class=\"data row3 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_9418b_row3_col1\" class=\"data row3 col1\" >0.6521</td>\n",
       "      <td id=\"T_9418b_row3_col2\" class=\"data row3 col2\" >0.8301</td>\n",
       "      <td id=\"T_9418b_row3_col3\" class=\"data row3 col3\" >0.6521</td>\n",
       "      <td id=\"T_9418b_row3_col4\" class=\"data row3 col4\" >0.6548</td>\n",
       "      <td id=\"T_9418b_row3_col5\" class=\"data row3 col5\" >0.6460</td>\n",
       "      <td id=\"T_9418b_row3_col6\" class=\"data row3 col6\" >0.4781</td>\n",
       "      <td id=\"T_9418b_row3_col7\" class=\"data row3 col7\" >0.4840</td>\n",
       "      <td id=\"T_9418b_row3_col8\" class=\"data row3 col8\" >9.0290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9418b_level0_row4\" class=\"row_heading level0 row4\" >xgboost</th>\n",
       "      <td id=\"T_9418b_row4_col0\" class=\"data row4 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_9418b_row4_col1\" class=\"data row4 col1\" >0.4592</td>\n",
       "      <td id=\"T_9418b_row4_col2\" class=\"data row4 col2\" >0.6504</td>\n",
       "      <td id=\"T_9418b_row4_col3\" class=\"data row4 col3\" >0.4592</td>\n",
       "      <td id=\"T_9418b_row4_col4\" class=\"data row4 col4\" >0.4579</td>\n",
       "      <td id=\"T_9418b_row4_col5\" class=\"data row4 col5\" >0.4533</td>\n",
       "      <td id=\"T_9418b_row4_col6\" class=\"data row4 col6\" >0.1887</td>\n",
       "      <td id=\"T_9418b_row4_col7\" class=\"data row4 col7\" >0.1908</td>\n",
       "      <td id=\"T_9418b_row4_col8\" class=\"data row4 col8\" >2.3990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9418b_level0_row5\" class=\"row_heading level0 row5\" >lightgbm</th>\n",
       "      <td id=\"T_9418b_row5_col0\" class=\"data row5 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_9418b_row5_col1\" class=\"data row5 col1\" >0.4566</td>\n",
       "      <td id=\"T_9418b_row5_col2\" class=\"data row5 col2\" >0.6476</td>\n",
       "      <td id=\"T_9418b_row5_col3\" class=\"data row5 col3\" >0.4566</td>\n",
       "      <td id=\"T_9418b_row5_col4\" class=\"data row5 col4\" >0.4553</td>\n",
       "      <td id=\"T_9418b_row5_col5\" class=\"data row5 col5\" >0.4494</td>\n",
       "      <td id=\"T_9418b_row5_col6\" class=\"data row5 col6\" >0.1849</td>\n",
       "      <td id=\"T_9418b_row5_col7\" class=\"data row5 col7\" >0.1875</td>\n",
       "      <td id=\"T_9418b_row5_col8\" class=\"data row5 col8\" >6.2550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9418b_level0_row6\" class=\"row_heading level0 row6\" >ada</th>\n",
       "      <td id=\"T_9418b_row6_col0\" class=\"data row6 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_9418b_row6_col1\" class=\"data row6 col1\" >0.3660</td>\n",
       "      <td id=\"T_9418b_row6_col2\" class=\"data row6 col2\" >0.5403</td>\n",
       "      <td id=\"T_9418b_row6_col3\" class=\"data row6 col3\" >0.3660</td>\n",
       "      <td id=\"T_9418b_row6_col4\" class=\"data row6 col4\" >0.3657</td>\n",
       "      <td id=\"T_9418b_row6_col5\" class=\"data row6 col5\" >0.3483</td>\n",
       "      <td id=\"T_9418b_row6_col6\" class=\"data row6 col6\" >0.0489</td>\n",
       "      <td id=\"T_9418b_row6_col7\" class=\"data row6 col7\" >0.0510</td>\n",
       "      <td id=\"T_9418b_row6_col8\" class=\"data row6 col8\" >73.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9418b_level0_row7\" class=\"row_heading level0 row7\" >lr</th>\n",
       "      <td id=\"T_9418b_row7_col0\" class=\"data row7 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_9418b_row7_col1\" class=\"data row7 col1\" >0.3355</td>\n",
       "      <td id=\"T_9418b_row7_col2\" class=\"data row7 col2\" >0.5076</td>\n",
       "      <td id=\"T_9418b_row7_col3\" class=\"data row7 col3\" >0.3355</td>\n",
       "      <td id=\"T_9418b_row7_col4\" class=\"data row7 col4\" >0.3363</td>\n",
       "      <td id=\"T_9418b_row7_col5\" class=\"data row7 col5\" >0.3249</td>\n",
       "      <td id=\"T_9418b_row7_col6\" class=\"data row7 col6\" >0.0032</td>\n",
       "      <td id=\"T_9418b_row7_col7\" class=\"data row7 col7\" >0.0033</td>\n",
       "      <td id=\"T_9418b_row7_col8\" class=\"data row7 col8\" >0.5760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9418b_level0_row8\" class=\"row_heading level0 row8\" >lda</th>\n",
       "      <td id=\"T_9418b_row8_col0\" class=\"data row8 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_9418b_row8_col1\" class=\"data row8 col1\" >0.3352</td>\n",
       "      <td id=\"T_9418b_row8_col2\" class=\"data row8 col2\" >0.5071</td>\n",
       "      <td id=\"T_9418b_row8_col3\" class=\"data row8 col3\" >0.3352</td>\n",
       "      <td id=\"T_9418b_row8_col4\" class=\"data row8 col4\" >0.3354</td>\n",
       "      <td id=\"T_9418b_row8_col5\" class=\"data row8 col5\" >0.3306</td>\n",
       "      <td id=\"T_9418b_row8_col6\" class=\"data row8 col6\" >0.0028</td>\n",
       "      <td id=\"T_9418b_row8_col7\" class=\"data row8 col7\" >0.0028</td>\n",
       "      <td id=\"T_9418b_row8_col8\" class=\"data row8 col8\" >1.6630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9418b_level0_row9\" class=\"row_heading level0 row9\" >qda</th>\n",
       "      <td id=\"T_9418b_row9_col0\" class=\"data row9 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_9418b_row9_col1\" class=\"data row9 col1\" >0.3350</td>\n",
       "      <td id=\"T_9418b_row9_col2\" class=\"data row9 col2\" >0.5013</td>\n",
       "      <td id=\"T_9418b_row9_col3\" class=\"data row9 col3\" >0.3350</td>\n",
       "      <td id=\"T_9418b_row9_col4\" class=\"data row9 col4\" >0.2375</td>\n",
       "      <td id=\"T_9418b_row9_col5\" class=\"data row9 col5\" >0.2206</td>\n",
       "      <td id=\"T_9418b_row9_col6\" class=\"data row9 col6\" >0.0025</td>\n",
       "      <td id=\"T_9418b_row9_col7\" class=\"data row9 col7\" >0.0037</td>\n",
       "      <td id=\"T_9418b_row9_col8\" class=\"data row9 col8\" >1.1580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9418b_level0_row10\" class=\"row_heading level0 row10\" >ridge</th>\n",
       "      <td id=\"T_9418b_row10_col0\" class=\"data row10 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_9418b_row10_col1\" class=\"data row10 col1\" >0.3348</td>\n",
       "      <td id=\"T_9418b_row10_col2\" class=\"data row10 col2\" >0.0000</td>\n",
       "      <td id=\"T_9418b_row10_col3\" class=\"data row10 col3\" >0.3348</td>\n",
       "      <td id=\"T_9418b_row10_col4\" class=\"data row10 col4\" >0.3350</td>\n",
       "      <td id=\"T_9418b_row10_col5\" class=\"data row10 col5\" >0.3288</td>\n",
       "      <td id=\"T_9418b_row10_col6\" class=\"data row10 col6\" >0.0022</td>\n",
       "      <td id=\"T_9418b_row10_col7\" class=\"data row10 col7\" >0.0023</td>\n",
       "      <td id=\"T_9418b_row10_col8\" class=\"data row10 col8\" >0.5290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9418b_level0_row11\" class=\"row_heading level0 row11\" >svm</th>\n",
       "      <td id=\"T_9418b_row11_col0\" class=\"data row11 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_9418b_row11_col1\" class=\"data row11 col1\" >0.3337</td>\n",
       "      <td id=\"T_9418b_row11_col2\" class=\"data row11 col2\" >0.0000</td>\n",
       "      <td id=\"T_9418b_row11_col3\" class=\"data row11 col3\" >0.3337</td>\n",
       "      <td id=\"T_9418b_row11_col4\" class=\"data row11 col4\" >0.3318</td>\n",
       "      <td id=\"T_9418b_row11_col5\" class=\"data row11 col5\" >0.2871</td>\n",
       "      <td id=\"T_9418b_row11_col6\" class=\"data row11 col6\" >0.0006</td>\n",
       "      <td id=\"T_9418b_row11_col7\" class=\"data row11 col7\" >0.0007</td>\n",
       "      <td id=\"T_9418b_row11_col8\" class=\"data row11 col8\" >5.5850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9418b_level0_row12\" class=\"row_heading level0 row12\" >dummy</th>\n",
       "      <td id=\"T_9418b_row12_col0\" class=\"data row12 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_9418b_row12_col1\" class=\"data row12 col1\" >0.3333</td>\n",
       "      <td id=\"T_9418b_row12_col2\" class=\"data row12 col2\" >0.5000</td>\n",
       "      <td id=\"T_9418b_row12_col3\" class=\"data row12 col3\" >0.3333</td>\n",
       "      <td id=\"T_9418b_row12_col4\" class=\"data row12 col4\" >0.1111</td>\n",
       "      <td id=\"T_9418b_row12_col5\" class=\"data row12 col5\" >0.1667</td>\n",
       "      <td id=\"T_9418b_row12_col6\" class=\"data row12 col6\" >0.0000</td>\n",
       "      <td id=\"T_9418b_row12_col7\" class=\"data row12 col7\" >0.0000</td>\n",
       "      <td id=\"T_9418b_row12_col8\" class=\"data row12 col8\" >0.3340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9418b_level0_row13\" class=\"row_heading level0 row13\" >nb</th>\n",
       "      <td id=\"T_9418b_row13_col0\" class=\"data row13 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_9418b_row13_col1\" class=\"data row13 col1\" >0.3316</td>\n",
       "      <td id=\"T_9418b_row13_col2\" class=\"data row13 col2\" >0.4986</td>\n",
       "      <td id=\"T_9418b_row13_col3\" class=\"data row13 col3\" >0.3316</td>\n",
       "      <td id=\"T_9418b_row13_col4\" class=\"data row13 col4\" >0.3307</td>\n",
       "      <td id=\"T_9418b_row13_col5\" class=\"data row13 col5\" >0.2349</td>\n",
       "      <td id=\"T_9418b_row13_col6\" class=\"data row13 col6\" >-0.0025</td>\n",
       "      <td id=\"T_9418b_row13_col7\" class=\"data row13 col7\" >-0.0041</td>\n",
       "      <td id=\"T_9418b_row13_col8\" class=\"data row13 col8\" >0.4680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff726a49120>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pycaret.classification import *\n",
    "from pycaret.classification import ClassificationExperiment\n",
    "from lightgbm import LGBMClassifier\n",
    "exp = ClassificationExperiment()\n",
    "\n",
    "\n",
    "# data = pd.read_csv('../../data/training_dataset_pc_tsfresh.csv')\n",
    "\n",
    "s = setup(data, target = 'signal', session_id = 123, use_gpu=True)\n",
    "best = compare_models(exclude=['gbc'])\n",
    "# best = create_model(LGBMClassifier())\n",
    "# plot confusion matrix\n",
    "plot_model(best, plot = 'confusion_matrix', plot_kwargs = {'percent': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
