{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_ta as ta\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "def get_class(val):\n",
    "    ranges = {(0, 0.5): '0-0.5', (0.5, 1.0): '0.5-1.0', (1.0, 1.5): '1.0-1.5', (1.5, 2.0): '1.5-2.0', (2.0, 2.5): '2.0-2.5', (2.5, 3.0): '2.5-3.0', (3.0, 3.5): '3.0-3.5', (3.5, 4.0): '3.5-4.0', (4.0, 4.5): '4.0-4.5', (4.5, 5.0): '4.5-5.0', (5.0, 5.5): '5.0-5.5', (5.5, 6.0): '5.5-6.0', (6.0, 6.5): '6.0-6.5', (6.5, 7.0): '6.5-7.0', (7.0, 7.5): '7.0-7.5', (7.5, 8.0): '7.5-8.0', (8.0, 8.5): '8.0-8.5', (8.5, 9.0): '8.5-9.0', (9.0, 9.5): '9.0-9.5', (9.5, 10.0): '9.5-10.0', (10, float('inf')): 'gt-10', (-float('inf'), -10): 'lt--10', (-10, -9.5): '-10--9.5', (-9.5, -9.0): '-9.5--9.0', (-9.0, -8.5): '-9.0--8.5', (-8.5, -8.0): '-8.5--8.0', (-8.0, -7.5): '-8.0--7.5', (-7.5, -7.0): '-7.5--7.0', (-7.0, -6.5): '-7.0--6.5', (-6.5, -6.0): '-6.5--6.0', (-6.0, -5.5): '-6.0--5.5', (-5.5, -5.0): '-5.5--5.0', (-5.0, -4.5): '-5.0--4.5', (-4.5, -4.0): '-4.5--4.0', (-4.0, -3.5): '-4.0--3.5', (-3.5, -3.0): '-3.5--3.0', (-3.0, -2.5): '-3.0--2.5', (-2.5, -2.0): '-2.5--2.0', (-2.0, -1.5): '-2.0--1.5', (-1.5, -1.0): '-1.5--1.0', (-1.0, -0.5): '-1.0--0.5', (-0.5, 0.0): '-0.5-0.0'}\n",
    "    for key, value in ranges.items():\n",
    "        if key[0] <= val < key[1]:\n",
    "            return value\n",
    "\n",
    "    return 'uk'\n",
    "\n",
    "def generate_features(df, coin_pair, fn):\n",
    "    candlestick_frame = 12\n",
    "    pnl_threshold = 3\n",
    "\n",
    "\n",
    "    try:\n",
    "        df.ta.strategy(\"all\")\n",
    "        # 2/0\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        ts = list(df['time'])\n",
    "        open = list(df['open'])\n",
    "        high = list(df['high'])\n",
    "        low = list(df['low'])\n",
    "        close = list(df['close'])\n",
    "        volume = list(df['volume'])\n",
    "        tot = len(ts)\n",
    "        long_runup_lst = []\n",
    "        long_drawdown_lst = []\n",
    "        short_runup_lst = []\n",
    "        short_drawdown_lst = []\n",
    "        pnls = []\n",
    "        signal = []\n",
    "\n",
    "        for idx in range(tot):\n",
    "            if (idx >= candlestick_frame) and (idx <= tot - candlestick_frame-1):\n",
    "                pnl = round((open[idx+candlestick_frame]*100/open[idx+1])-100, 2)\n",
    "                pnls.append(pnl)\n",
    "                signal.append(get_class(pnl))\n",
    "            else:\n",
    "                pnls.append('uk')\n",
    "                signal.append('uk')\n",
    "                   \n",
    "        \n",
    "        # df['pnl'] = pnls\n",
    "        df['signal'] = signal\n",
    "\n",
    "        df = df.drop(columns = ['time', 'open', 'high', 'low', 'close', 'volume', 'DPO_20', 'HILOl_13_21', 'ICS_26', 'PSARl_0.02_0.2', 'QQEl_14_5_4.236', 'SUPERTl_7_3.0'], axis=1)\n",
    "        df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        \n",
    "        dataset_fn = f'../../data/{fn}.csv'\n",
    "        df.to_csv(dataset_fn, index=False)\n",
    "        print(f'{coin_pair} Features Generated and saved')\n",
    "        return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X] Please install TA-Lib to use 2crows. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use 3blackcrows. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use 3inside. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use 3linestrike. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use 3outside. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use 3starsinsouth. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use 3whitesoldiers. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use abandonedbaby. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use advanceblock. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use belthold. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use breakaway. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use closingmarubozu. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use concealbabyswall. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use counterattack. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use darkcloudcover. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use dojistar. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use dragonflydoji. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use engulfing. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use eveningdojistar. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use eveningstar. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use gapsidesidewhite. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use gravestonedoji. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use hammer. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use hangingman. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use harami. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use haramicross. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use highwave. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use hikkake. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use hikkakemod. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use homingpigeon. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use identical3crows. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use inneck. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use invertedhammer. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use kicking. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use kickingbylength. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use ladderbottom. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use longleggeddoji. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use longline. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use marubozu. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use matchinglow. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use mathold. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use morningdojistar. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use morningstar. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use onneck. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use piercing. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use rickshawman. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use risefall3methods. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use separatinglines. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use shootingstar. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use shortline. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use spinningtop. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use stalledpattern. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use sticksandwich. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use takuri. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use tasukigap. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use thrusting. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use tristar. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use unique3river. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use upsidegap2crows. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use xsidegap3methods. (pip install TA-Lib)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hk-lenovo-laptop/.local/lib/python3.10/site-packages/pandas_ta/overlap/linreg.py:52: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  rd = (divisor * (length * y2_sum - y_sum * y_sum)) ** 0.5\n",
      "/usr/lib/python3.10/multiprocessing/pool.py:48: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  return list(map(*args))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] VWAP volume series is not datetime ordered. Results may not be as expected.\n",
      "[!] VWAP price series is not datetime ordered. Results may not be as expected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [01:57,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'RangeIndex' object has no attribute 'to_period'\n",
      "BTCUSDT Features Generated and saved\n"
     ]
    }
   ],
   "source": [
    "raw_df = pd.read_csv('../../data/BTCUSDT_raw_2016_till_JAN_2023.csv')\n",
    "ta_feats = generate_features(raw_df, 'BTCUSDT', 'ta_feats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABER_ZG_5_15</th>\n",
       "      <th>ABER_SG_5_15</th>\n",
       "      <th>ABER_XG_5_15</th>\n",
       "      <th>ABER_ATR_5_15</th>\n",
       "      <th>ACCBL_20</th>\n",
       "      <th>ACCBM_20</th>\n",
       "      <th>ACCBU_20</th>\n",
       "      <th>AD</th>\n",
       "      <th>ADOSC_3_10</th>\n",
       "      <th>ADX_14</th>\n",
       "      <th>...</th>\n",
       "      <th>TSIs_13_25_13</th>\n",
       "      <th>TTM_TRND_6</th>\n",
       "      <th>UI_14</th>\n",
       "      <th>UO_7_14_28</th>\n",
       "      <th>VAR_30</th>\n",
       "      <th>VHF_28</th>\n",
       "      <th>VIDYA_14</th>\n",
       "      <th>signal</th>\n",
       "      <th>runup</th>\n",
       "      <th>drawdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uk</td>\n",
       "      <td>uk</td>\n",
       "      <td>uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uk</td>\n",
       "      <td>uk</td>\n",
       "      <td>uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uk</td>\n",
       "      <td>uk</td>\n",
       "      <td>uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uk</td>\n",
       "      <td>uk</td>\n",
       "      <td>uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uk</td>\n",
       "      <td>uk</td>\n",
       "      <td>uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116166</th>\n",
       "      <td>16573.333333</td>\n",
       "      <td>16587.187190</td>\n",
       "      <td>16559.479477</td>\n",
       "      <td>13.853856</td>\n",
       "      <td>16547.558539</td>\n",
       "      <td>16587.850</td>\n",
       "      <td>16631.108539</td>\n",
       "      <td>4.479084e+06</td>\n",
       "      <td>-169.559167</td>\n",
       "      <td>15.215962</td>\n",
       "      <td>...</td>\n",
       "      <td>4.168457</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.223282</td>\n",
       "      <td>47.029491</td>\n",
       "      <td>281.997894</td>\n",
       "      <td>0.304792</td>\n",
       "      <td>16573.222339</td>\n",
       "      <td>uk</td>\n",
       "      <td>uk</td>\n",
       "      <td>uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116167</th>\n",
       "      <td>16571.073333</td>\n",
       "      <td>16584.896933</td>\n",
       "      <td>16557.249734</td>\n",
       "      <td>13.823599</td>\n",
       "      <td>16545.982290</td>\n",
       "      <td>16584.810</td>\n",
       "      <td>16626.782290</td>\n",
       "      <td>4.478640e+06</td>\n",
       "      <td>-262.931265</td>\n",
       "      <td>15.041751</td>\n",
       "      <td>...</td>\n",
       "      <td>2.935749</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.219726</td>\n",
       "      <td>41.680155</td>\n",
       "      <td>281.087331</td>\n",
       "      <td>0.305512</td>\n",
       "      <td>16572.973602</td>\n",
       "      <td>uk</td>\n",
       "      <td>uk</td>\n",
       "      <td>uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116168</th>\n",
       "      <td>16571.053333</td>\n",
       "      <td>16585.188693</td>\n",
       "      <td>16556.917974</td>\n",
       "      <td>14.135359</td>\n",
       "      <td>16545.879762</td>\n",
       "      <td>16583.200</td>\n",
       "      <td>16622.704762</td>\n",
       "      <td>4.478342e+06</td>\n",
       "      <td>-372.022615</td>\n",
       "      <td>14.047396</td>\n",
       "      <td>...</td>\n",
       "      <td>1.835935</td>\n",
       "      <td>1</td>\n",
       "      <td>0.214918</td>\n",
       "      <td>42.747860</td>\n",
       "      <td>277.116929</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>16572.971634</td>\n",
       "      <td>uk</td>\n",
       "      <td>uk</td>\n",
       "      <td>uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116169</th>\n",
       "      <td>16571.286667</td>\n",
       "      <td>16586.013002</td>\n",
       "      <td>16556.560331</td>\n",
       "      <td>14.726335</td>\n",
       "      <td>16545.638978</td>\n",
       "      <td>16582.175</td>\n",
       "      <td>16621.188978</td>\n",
       "      <td>4.477520e+06</td>\n",
       "      <td>-644.456802</td>\n",
       "      <td>13.469759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695584</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.216264</td>\n",
       "      <td>30.677072</td>\n",
       "      <td>275.355825</td>\n",
       "      <td>0.274236</td>\n",
       "      <td>16572.436576</td>\n",
       "      <td>uk</td>\n",
       "      <td>uk</td>\n",
       "      <td>uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116170</th>\n",
       "      <td>16569.580000</td>\n",
       "      <td>16583.544580</td>\n",
       "      <td>16555.615420</td>\n",
       "      <td>13.964580</td>\n",
       "      <td>16548.174313</td>\n",
       "      <td>16579.935</td>\n",
       "      <td>16614.674313</td>\n",
       "      <td>4.477754e+06</td>\n",
       "      <td>-622.950608</td>\n",
       "      <td>12.933382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.446075</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.215584</td>\n",
       "      <td>34.010994</td>\n",
       "      <td>246.422676</td>\n",
       "      <td>0.278122</td>\n",
       "      <td>16571.980523</td>\n",
       "      <td>uk</td>\n",
       "      <td>uk</td>\n",
       "      <td>uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116171 rows Ã— 206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ABER_ZG_5_15  ABER_SG_5_15  ABER_XG_5_15  ABER_ATR_5_15      ACCBL_20  \\\n",
       "0                NaN           NaN           NaN            NaN           NaN   \n",
       "1                NaN           NaN           NaN            NaN           NaN   \n",
       "2                NaN           NaN           NaN            NaN           NaN   \n",
       "3                NaN           NaN           NaN            NaN           NaN   \n",
       "4       10000.000000           NaN           NaN            NaN           NaN   \n",
       "...              ...           ...           ...            ...           ...   \n",
       "116166  16573.333333  16587.187190  16559.479477      13.853856  16547.558539   \n",
       "116167  16571.073333  16584.896933  16557.249734      13.823599  16545.982290   \n",
       "116168  16571.053333  16585.188693  16556.917974      14.135359  16545.879762   \n",
       "116169  16571.286667  16586.013002  16556.560331      14.726335  16545.638978   \n",
       "116170  16569.580000  16583.544580  16555.615420      13.964580  16548.174313   \n",
       "\n",
       "         ACCBM_20      ACCBU_20            AD  ADOSC_3_10     ADX_14  ...  \\\n",
       "0             NaN           NaN  0.000000e+00         NaN        NaN  ...   \n",
       "1             NaN           NaN  0.000000e+00         NaN        NaN  ...   \n",
       "2             NaN           NaN  0.000000e+00         NaN        NaN  ...   \n",
       "3             NaN           NaN  0.000000e+00         NaN        NaN  ...   \n",
       "4             NaN           NaN  0.000000e+00         NaN        NaN  ...   \n",
       "...           ...           ...           ...         ...        ...  ...   \n",
       "116166  16587.850  16631.108539  4.479084e+06 -169.559167  15.215962  ...   \n",
       "116167  16584.810  16626.782290  4.478640e+06 -262.931265  15.041751  ...   \n",
       "116168  16583.200  16622.704762  4.478342e+06 -372.022615  14.047396  ...   \n",
       "116169  16582.175  16621.188978  4.477520e+06 -644.456802  13.469759  ...   \n",
       "116170  16579.935  16614.674313  4.477754e+06 -622.950608  12.933382  ...   \n",
       "\n",
       "        TSIs_13_25_13  TTM_TRND_6     UI_14  UO_7_14_28      VAR_30    VHF_28  \\\n",
       "0                 NaN          -1       NaN         NaN         NaN       NaN   \n",
       "1                 NaN          -1       NaN         NaN         NaN       NaN   \n",
       "2                 NaN          -1       NaN         NaN         NaN       NaN   \n",
       "3                 NaN          -1       NaN         NaN         NaN       NaN   \n",
       "4                 NaN          -1       NaN         NaN         NaN       NaN   \n",
       "...               ...         ...       ...         ...         ...       ...   \n",
       "116166       4.168457          -1  0.223282   47.029491  281.997894  0.304792   \n",
       "116167       2.935749          -1  0.219726   41.680155  281.087331  0.305512   \n",
       "116168       1.835935           1  0.214918   42.747860  277.116929  0.246154   \n",
       "116169       0.695584          -1  0.216264   30.677072  275.355825  0.274236   \n",
       "116170      -0.446075          -1  0.215584   34.010994  246.422676  0.278122   \n",
       "\n",
       "            VIDYA_14  signal  runup  drawdown  \n",
       "0                NaN      uk     uk        uk  \n",
       "1                NaN      uk     uk        uk  \n",
       "2                NaN      uk     uk        uk  \n",
       "3                NaN      uk     uk        uk  \n",
       "4                NaN      uk     uk        uk  \n",
       "...              ...     ...    ...       ...  \n",
       "116166  16573.222339      uk     uk        uk  \n",
       "116167  16572.973602      uk     uk        uk  \n",
       "116168  16572.971634      uk     uk        uk  \n",
       "116169  16572.436576      uk     uk        uk  \n",
       "116170  16571.980523      uk     uk        uk  \n",
       "\n",
       "[116171 rows x 206 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ta_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_CUDAP=1\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_CUDAP=1\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_CUDAP=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_CUDAP=1\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_CUDAP=1\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_CUDAP=1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1ddb4_row9_col1, #T_1ddb4_row16_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1ddb4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1ddb4_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_1ddb4_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1ddb4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_1ddb4_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_1ddb4_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ddb4_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_1ddb4_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_1ddb4_row1_col1\" class=\"data row1 col1\" >signal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ddb4_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_1ddb4_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_1ddb4_row2_col1\" class=\"data row2 col1\" >Multiclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ddb4_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_1ddb4_row3_col0\" class=\"data row3 col0\" >Target mapping</td>\n",
       "      <td id=\"T_1ddb4_row3_col1\" class=\"data row3 col1\" >dont_trade: 0, long: 1, short: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ddb4_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_1ddb4_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_1ddb4_row4_col1\" class=\"data row4 col1\" >(318093, 204)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ddb4_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_1ddb4_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_1ddb4_row5_col1\" class=\"data row5 col1\" >(318093, 204)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ddb4_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_1ddb4_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_1ddb4_row6_col1\" class=\"data row6 col1\" >(222665, 204)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ddb4_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_1ddb4_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_1ddb4_row7_col1\" class=\"data row7 col1\" >(95428, 204)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ddb4_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_1ddb4_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_1ddb4_row8_col1\" class=\"data row8 col1\" >203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ddb4_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_1ddb4_row9_col0\" class=\"data row9 col0\" >Preprocess</td>\n",
       "      <td id=\"T_1ddb4_row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ddb4_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_1ddb4_row10_col0\" class=\"data row10 col0\" >Imputation type</td>\n",
       "      <td id=\"T_1ddb4_row10_col1\" class=\"data row10 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ddb4_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_1ddb4_row11_col0\" class=\"data row11 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_1ddb4_row11_col1\" class=\"data row11 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ddb4_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_1ddb4_row12_col0\" class=\"data row12 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_1ddb4_row12_col1\" class=\"data row12 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ddb4_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_1ddb4_row13_col0\" class=\"data row13 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_1ddb4_row13_col1\" class=\"data row13 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ddb4_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_1ddb4_row14_col0\" class=\"data row14 col0\" >Fold Number</td>\n",
       "      <td id=\"T_1ddb4_row14_col1\" class=\"data row14 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ddb4_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_1ddb4_row15_col0\" class=\"data row15 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_1ddb4_row15_col1\" class=\"data row15 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ddb4_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_1ddb4_row16_col0\" class=\"data row16 col0\" >Use GPU</td>\n",
       "      <td id=\"T_1ddb4_row16_col1\" class=\"data row16 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ddb4_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_1ddb4_row17_col0\" class=\"data row17 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_1ddb4_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ddb4_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_1ddb4_row18_col0\" class=\"data row18 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_1ddb4_row18_col1\" class=\"data row18 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ddb4_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_1ddb4_row19_col0\" class=\"data row19 col0\" >USI</td>\n",
       "      <td id=\"T_1ddb4_row19_col1\" class=\"data row19 col1\" >b2cc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7ce6e93550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_CUDAP=1\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_CUDAP=1\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_83635_row10_col0, #T_83635_row10_col1, #T_83635_row10_col2, #T_83635_row10_col3, #T_83635_row10_col4, #T_83635_row10_col5, #T_83635_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_83635\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_83635_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_83635_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_83635_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_83635_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_83635_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_83635_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_83635_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_83635_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_83635_row0_col0\" class=\"data row0 col0\" >0.8796</td>\n",
       "      <td id=\"T_83635_row0_col1\" class=\"data row0 col1\" >0.9656</td>\n",
       "      <td id=\"T_83635_row0_col2\" class=\"data row0 col2\" >0.8796</td>\n",
       "      <td id=\"T_83635_row0_col3\" class=\"data row0 col3\" >0.8780</td>\n",
       "      <td id=\"T_83635_row0_col4\" class=\"data row0 col4\" >0.8782</td>\n",
       "      <td id=\"T_83635_row0_col5\" class=\"data row0 col5\" >0.8194</td>\n",
       "      <td id=\"T_83635_row0_col6\" class=\"data row0 col6\" >0.8199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83635_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_83635_row1_col0\" class=\"data row1 col0\" >0.8801</td>\n",
       "      <td id=\"T_83635_row1_col1\" class=\"data row1 col1\" >0.9656</td>\n",
       "      <td id=\"T_83635_row1_col2\" class=\"data row1 col2\" >0.8801</td>\n",
       "      <td id=\"T_83635_row1_col3\" class=\"data row1 col3\" >0.8785</td>\n",
       "      <td id=\"T_83635_row1_col4\" class=\"data row1 col4\" >0.8786</td>\n",
       "      <td id=\"T_83635_row1_col5\" class=\"data row1 col5\" >0.8202</td>\n",
       "      <td id=\"T_83635_row1_col6\" class=\"data row1 col6\" >0.8209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83635_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_83635_row2_col0\" class=\"data row2 col0\" >0.8800</td>\n",
       "      <td id=\"T_83635_row2_col1\" class=\"data row2 col1\" >0.9657</td>\n",
       "      <td id=\"T_83635_row2_col2\" class=\"data row2 col2\" >0.8800</td>\n",
       "      <td id=\"T_83635_row2_col3\" class=\"data row2 col3\" >0.8784</td>\n",
       "      <td id=\"T_83635_row2_col4\" class=\"data row2 col4\" >0.8786</td>\n",
       "      <td id=\"T_83635_row2_col5\" class=\"data row2 col5\" >0.8201</td>\n",
       "      <td id=\"T_83635_row2_col6\" class=\"data row2 col6\" >0.8207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83635_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_83635_row3_col0\" class=\"data row3 col0\" >0.8728</td>\n",
       "      <td id=\"T_83635_row3_col1\" class=\"data row3 col1\" >0.9633</td>\n",
       "      <td id=\"T_83635_row3_col2\" class=\"data row3 col2\" >0.8728</td>\n",
       "      <td id=\"T_83635_row3_col3\" class=\"data row3 col3\" >0.8709</td>\n",
       "      <td id=\"T_83635_row3_col4\" class=\"data row3 col4\" >0.8712</td>\n",
       "      <td id=\"T_83635_row3_col5\" class=\"data row3 col5\" >0.8092</td>\n",
       "      <td id=\"T_83635_row3_col6\" class=\"data row3 col6\" >0.8097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83635_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_83635_row4_col0\" class=\"data row4 col0\" >0.8795</td>\n",
       "      <td id=\"T_83635_row4_col1\" class=\"data row4 col1\" >0.9662</td>\n",
       "      <td id=\"T_83635_row4_col2\" class=\"data row4 col2\" >0.8795</td>\n",
       "      <td id=\"T_83635_row4_col3\" class=\"data row4 col3\" >0.8778</td>\n",
       "      <td id=\"T_83635_row4_col4\" class=\"data row4 col4\" >0.8780</td>\n",
       "      <td id=\"T_83635_row4_col5\" class=\"data row4 col5\" >0.8192</td>\n",
       "      <td id=\"T_83635_row4_col6\" class=\"data row4 col6\" >0.8198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83635_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_83635_row5_col0\" class=\"data row5 col0\" >0.8784</td>\n",
       "      <td id=\"T_83635_row5_col1\" class=\"data row5 col1\" >0.9654</td>\n",
       "      <td id=\"T_83635_row5_col2\" class=\"data row5 col2\" >0.8784</td>\n",
       "      <td id=\"T_83635_row5_col3\" class=\"data row5 col3\" >0.8767</td>\n",
       "      <td id=\"T_83635_row5_col4\" class=\"data row5 col4\" >0.8769</td>\n",
       "      <td id=\"T_83635_row5_col5\" class=\"data row5 col5\" >0.8176</td>\n",
       "      <td id=\"T_83635_row5_col6\" class=\"data row5 col6\" >0.8182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83635_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_83635_row6_col0\" class=\"data row6 col0\" >0.8754</td>\n",
       "      <td id=\"T_83635_row6_col1\" class=\"data row6 col1\" >0.9642</td>\n",
       "      <td id=\"T_83635_row6_col2\" class=\"data row6 col2\" >0.8754</td>\n",
       "      <td id=\"T_83635_row6_col3\" class=\"data row6 col3\" >0.8735</td>\n",
       "      <td id=\"T_83635_row6_col4\" class=\"data row6 col4\" >0.8738</td>\n",
       "      <td id=\"T_83635_row6_col5\" class=\"data row6 col5\" >0.8131</td>\n",
       "      <td id=\"T_83635_row6_col6\" class=\"data row6 col6\" >0.8137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83635_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_83635_row7_col0\" class=\"data row7 col0\" >0.8757</td>\n",
       "      <td id=\"T_83635_row7_col1\" class=\"data row7 col1\" >0.9647</td>\n",
       "      <td id=\"T_83635_row7_col2\" class=\"data row7 col2\" >0.8757</td>\n",
       "      <td id=\"T_83635_row7_col3\" class=\"data row7 col3\" >0.8739</td>\n",
       "      <td id=\"T_83635_row7_col4\" class=\"data row7 col4\" >0.8741</td>\n",
       "      <td id=\"T_83635_row7_col5\" class=\"data row7 col5\" >0.8135</td>\n",
       "      <td id=\"T_83635_row7_col6\" class=\"data row7 col6\" >0.8142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83635_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_83635_row8_col0\" class=\"data row8 col0\" >0.8758</td>\n",
       "      <td id=\"T_83635_row8_col1\" class=\"data row8 col1\" >0.9649</td>\n",
       "      <td id=\"T_83635_row8_col2\" class=\"data row8 col2\" >0.8758</td>\n",
       "      <td id=\"T_83635_row8_col3\" class=\"data row8 col3\" >0.8739</td>\n",
       "      <td id=\"T_83635_row8_col4\" class=\"data row8 col4\" >0.8742</td>\n",
       "      <td id=\"T_83635_row8_col5\" class=\"data row8 col5\" >0.8137</td>\n",
       "      <td id=\"T_83635_row8_col6\" class=\"data row8 col6\" >0.8142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83635_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_83635_row9_col0\" class=\"data row9 col0\" >0.8822</td>\n",
       "      <td id=\"T_83635_row9_col1\" class=\"data row9 col1\" >0.9677</td>\n",
       "      <td id=\"T_83635_row9_col2\" class=\"data row9 col2\" >0.8822</td>\n",
       "      <td id=\"T_83635_row9_col3\" class=\"data row9 col3\" >0.8806</td>\n",
       "      <td id=\"T_83635_row9_col4\" class=\"data row9 col4\" >0.8808</td>\n",
       "      <td id=\"T_83635_row9_col5\" class=\"data row9 col5\" >0.8234</td>\n",
       "      <td id=\"T_83635_row9_col6\" class=\"data row9 col6\" >0.8239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83635_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_83635_row10_col0\" class=\"data row10 col0\" >0.8780</td>\n",
       "      <td id=\"T_83635_row10_col1\" class=\"data row10 col1\" >0.9653</td>\n",
       "      <td id=\"T_83635_row10_col2\" class=\"data row10 col2\" >0.8780</td>\n",
       "      <td id=\"T_83635_row10_col3\" class=\"data row10 col3\" >0.8762</td>\n",
       "      <td id=\"T_83635_row10_col4\" class=\"data row10 col4\" >0.8764</td>\n",
       "      <td id=\"T_83635_row10_col5\" class=\"data row10 col5\" >0.8169</td>\n",
       "      <td id=\"T_83635_row10_col6\" class=\"data row10 col6\" >0.8175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83635_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_83635_row11_col0\" class=\"data row11 col0\" >0.0028</td>\n",
       "      <td id=\"T_83635_row11_col1\" class=\"data row11 col1\" >0.0011</td>\n",
       "      <td id=\"T_83635_row11_col2\" class=\"data row11 col2\" >0.0028</td>\n",
       "      <td id=\"T_83635_row11_col3\" class=\"data row11 col3\" >0.0028</td>\n",
       "      <td id=\"T_83635_row11_col4\" class=\"data row11 col4\" >0.0028</td>\n",
       "      <td id=\"T_83635_row11_col5\" class=\"data row11 col5\" >0.0041</td>\n",
       "      <td id=\"T_83635_row11_col6\" class=\"data row11 col6\" >0.0041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7ce68d8040>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pycaret.classification import *\n",
    "from pycaret.classification import ClassificationExperiment\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "exp = ClassificationExperiment()\n",
    "\n",
    "\n",
    "data = pd.read_csv('../../data/ta_feats.csv')\n",
    "\n",
    "s = setup(data, target = 'signal', session_id = 123, use_gpu=True)\n",
    "model = compare_models(exclude=['gbc'])\n",
    "# model = create_model(DecisionTreeClassifier())\n",
    "# model = create_model(LGBMClassifier())\n",
    "\n",
    "# save pipeline\n",
    "model_name = 'model_ta_feats'\n",
    "save_model(model, f'../../models/{model_name}')\n",
    "plot_model(model, plot = 'confusion_matrix', plot_kwargs = {'percent': True})\n",
    "# plot_model(model, plot = 'feature_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep Dataset with Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X] Please install TA-Lib to use 2crows. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use 3blackcrows. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use 3inside. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use 3linestrike. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use 3outside. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use 3starsinsouth. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use 3whitesoldiers. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use abandonedbaby. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use advanceblock. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use belthold. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use breakaway. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use closingmarubozu. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use concealbabyswall. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use counterattack. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use darkcloudcover. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use dojistar. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use dragonflydoji. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use engulfing. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use eveningdojistar. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use eveningstar. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use gapsidesidewhite. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use gravestonedoji. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use hammer. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use hangingman. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use harami. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use haramicross. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use highwave. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use hikkake. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use hikkakemod. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use homingpigeon. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use identical3crows. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use inneck. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use invertedhammer. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use kicking. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use kickingbylength. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use ladderbottom. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use longleggeddoji. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use longline. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use marubozu. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use matchinglow. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use mathold. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use morningdojistar. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use morningstar. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use onneck. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use piercing. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use rickshawman. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use risefall3methods. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use separatinglines. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use shootingstar. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use shortline. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use spinningtop. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use stalledpattern. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use sticksandwich. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use takuri. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use tasukigap. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use thrusting. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use tristar. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use unique3river. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use upsidegap2crows. (pip install TA-Lib)\n",
      "[X] Please install TA-Lib to use xsidegap3methods. (pip install TA-Lib)\n",
      "[!] VWAP volume series is not datetime ordered. Results may not be as expected.\n",
      "[!] VWAP price series is not datetime ordered. Results may not be as expected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:36,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'RangeIndex' object has no attribute 'to_period'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_8909d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8909d_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_8909d_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_8909d_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_8909d_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_8909d_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_8909d_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_8909d_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_8909d_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8909d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8909d_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_8909d_row0_col1\" class=\"data row0 col1\" >0.9205</td>\n",
       "      <td id=\"T_8909d_row0_col2\" class=\"data row0 col2\" >0.8590</td>\n",
       "      <td id=\"T_8909d_row0_col3\" class=\"data row0 col3\" >0.9205</td>\n",
       "      <td id=\"T_8909d_row0_col4\" class=\"data row0 col4\" >0.9038</td>\n",
       "      <td id=\"T_8909d_row0_col5\" class=\"data row0 col5\" >0.9069</td>\n",
       "      <td id=\"T_8909d_row0_col6\" class=\"data row0 col6\" >0.3551</td>\n",
       "      <td id=\"T_8909d_row0_col7\" class=\"data row0 col7\" >0.3826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7ce9413220>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_ta as ta\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "\n",
    "def generate_features_no_balancing(df, coin_pair, fn):\n",
    "    candlestick_frame = 12\n",
    "    pnl_threshold = 3\n",
    "\n",
    "\n",
    "    try:\n",
    "        df.ta.strategy(\"all\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        ts = list(df['time'])\n",
    "        open = list(df['open'])\n",
    "        high = list(df['high'])\n",
    "        low = list(df['low'])\n",
    "        close = list(df['close'])\n",
    "        volume = list(df['volume'])\n",
    "        tot = len(ts)\n",
    "        long_runup_lst = []\n",
    "        long_drawdown_lst = []\n",
    "        short_runup_lst = []\n",
    "        short_drawdown_lst = []\n",
    "\n",
    "        for idx in range(tot):\n",
    "            if (idx >= candlestick_frame) and (idx <= tot - candlestick_frame):\n",
    "                max_high = max(high[idx+1:idx+candlestick_frame])\n",
    "                min_low = min(low[idx+1:idx+candlestick_frame])\n",
    "                entry_price = open[idx+1]\n",
    "                long_runup_lst.append(round((max_high*100/entry_price)-100, 6))\n",
    "                long_drawdown_lst.append(round((min_low*100/entry_price)-100, 6))\n",
    "                short_runup_lst.append(round((entry_price*100/min_low)-100, 6))\n",
    "                short_drawdown_lst.append(round((entry_price*100/max_high)-100, 6))\n",
    "            else:\n",
    "                long_runup_lst.append(0)\n",
    "                long_drawdown_lst.append(0)\n",
    "                short_runup_lst.append(0)\n",
    "                short_drawdown_lst.append(0)     \n",
    "\n",
    "        signal = []\n",
    "        for idx in range(tot):\n",
    "            if (idx >= candlestick_frame) and (idx <= tot - candlestick_frame):\n",
    "                if long_runup_lst[idx] >= pnl_threshold:\n",
    "                    signal.append('long')\n",
    "                elif short_runup_lst[idx] >= pnl_threshold:\n",
    "                    signal.append('short')\n",
    "                else:\n",
    "                    signal.append('dont_trade')\n",
    "            else:\n",
    "                signal.append('dont_trade')\n",
    "\n",
    "        df['signal'] = signal\n",
    "\n",
    "        df = df.drop(columns = ['time', 'open', 'high', 'low', 'close', 'volume', 'DPO_20', 'HILOl_13_21', 'ICS_26', 'PSARl_0.02_0.2', 'QQEl_14_5_4.236', 'SUPERTl_7_3.0'], axis=1)\n",
    "        df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "model_name = f'model_ta_feats'\n",
    "model = load_model(f'../../models/{model_name}')\n",
    "\n",
    "raw_df = pd.read_csv('../../data/BTCUSDT_raw_2016_till_JAN_2023.csv')\n",
    "data = generate_features_no_balancing(raw_df, 'BTCUSDT', 'ta_feats')\n",
    "\n",
    "correct_signals = list(data['signal'])\n",
    "predictions = predict_model(model, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['correct_signals'] = correct_signals\n",
    "predictions.to_csv('../../data/predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Handle cases where val is not within any defined range\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
